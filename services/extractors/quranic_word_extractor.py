# services/extractors/quranic_word_extractor.py
"""
Stage 2 'extract_word()' â€“ finds the QurÊ¾Änic word/root the user
is asking about using layered heuristics:
Regex rules âž” GPT-4o mini âž” fallback to user prompt.
"""
from __future__ import annotations

import json
import os
import re
import sys
from typing import Optional, Tuple

from openai import OpenAI
from dotenv import load_dotenv
import os

# Load environment variables from .env file
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ------------- 1. fast regex patterns --------------------
_PATTERNS: list[re.Pattern] = [
    # Ù…Ø§ Ù…Ø¹Ù†Ù‰ / Ù…Ø§ ØªÙØ³ÙŠØ± ... ÙƒÙ„Ù…Ø© X
    re.compile(
        r'(?:(?:Ù…Ø§\s+)?(?:Ù…Ø¹Ù†Ù‰|ØªÙØ³ÙŠØ±|Ù…Ø¯Ù„ÙˆÙ„|Ù…ØºØ²Ù‰|Ø§Ù„Ù…ØºØ²Ù‰|Ù…Ù‚ØµÙˆØ¯|Ø¯Ù„Ø§Ù„Ø©|ØªÙÙŠØ¯)\s+'
        r'(?:Ù…Ù†\s+|Ø¨)?(?:ØªØ¹Ø¨ÙŠØ±|ÙƒÙ„Ù…Ø©|Ù„ÙØ¸Ø©|Ù„ÙØ¸|Ù…ÙØ±Ø¯Ø©|Ø¹Ø¨Ø§Ø±Ø©)\s+)'
        r'([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Ù…Ø§Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ù„ÙØ¸ X
    re.compile(
        r'(?:(?:Ù…Ø§Ø°Ø§\s+)?ÙŠØ¹Ù†ÙŠ(?:\s+Ø§ØµØ·Ù„Ø§Ø­Ù‹Ø§)?\s+'
        r'(?:Ù„ÙØ¸Ø©?|ÙƒÙ„Ù…Ø©|Ù„ÙØ¸|Ù…ÙØ±Ø¯Ø©|Ø¹Ø¨Ø§Ø±Ø©)\s+)'
        r'([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # ÙØ³Ø± / Ø§Ø´Ø±Ø­ ... ÙƒÙ„Ù…Ø© X
    re.compile(
        r'(?:(?:ÙØ³Ø±(?:ÙˆØ§)?|ÙØ³ÙÙ‘Ø±|ÙØ³Ù‘Ø±|Ø§Ø´Ø±Ø­|Ø¨ÙŠÙ‘Ù†|ÙˆØ¶Ø­|ÙˆØ¶Ù‘Ø­|Ø¯Ù„Ù‘Ù†ÙŠ|Ø¯Ù„Ù†ÙŠ|'
        r'Ø£Ø±ÙŠØ¯|Ø£Ø­ØªØ§Ø¬|Ø±Ø¬Ø§Ø¡Ù‹?|Ù…Ù†\s+ÙØ¶Ù„Ùƒ|Ù‡Ù„\s+ÙŠÙ…ÙƒÙ†Ùƒ)\s+'
        r'(?:Ø¹Ù„Ù‰\s+|Ø¥Ù„Ù‰\s+)?(?:Ù„ÙŠ\s+)?'
        r'(?:Ø¨ÙŠØ§Ù†\s+|Ø´Ø±Ø­Ù‹Ø§?\s+)?'
        r'(?:Ù…Ø¹Ù†Ù‰\s+)?'
        r'(?:Ø¬Ø°Ø±\s+|Ø§Ø´ØªÙ‚Ø§Ù‚\s+|Ø£ØµÙ„\s+)?'
        r'(?:Ø§Ù„)?(?:ÙƒÙ„Ù…Ø©|Ù„ÙØ¸Ø©|Ù„ÙØ¸|Ù…ÙØ±Ø¯Ø©|Ø¹Ø¨Ø§Ø±Ø©|ØªØ¹Ø¨ÙŠØ±|ÙØ¹Ù„)\s+)'
        r'([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # bare "Ø¬Ø°Ø± ÙƒÙ„Ù…Ø© X"
    re.compile(
        r'(?:Ø¬Ø°Ø±|Ø§Ø´ØªÙ‚Ø§Ù‚|Ø£ØµÙ„)\s+'
        r'(?:Ø§Ù„)?(?:ÙƒÙ„Ù…Ø©|Ù„ÙØ¸Ø©|Ù„ÙØ¸|ÙØ¹Ù„)\s+'
        r'([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # "ØªØµØ±ÙŠÙØ§Øª Ø¬Ø°Ø± X" or directly "Ø¬Ø°Ø± X" (without the word 'ÙƒÙ„Ù…Ø©')
    re.compile(
        r'(?:ØªØµØ±ÙŠÙØ§Øª|ØªØµØ§Ø±ÙŠÙ)?\s*(?:Ø¬Ø°Ø±)\s+([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Special pattern for words with hamza
    re.compile(
        r'(?:ÙƒÙ„Ù…Ø©|Ù„ÙØ¸Ø©|Ù„ÙØ¸|Ù…ÙØ±Ø¯Ø©|Ø¹Ø¨Ø§Ø±Ø©)\s+'
        r'([Ø£Ø¥Ø¢][^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Generic "â€¦ ÙƒÙ„Ù…Ø© X" pattern (placed last to catch remaining cases)
    re.compile(
        r'(?:ÙƒÙ„Ù…Ø©|Ù„ÙØ¸Ø©|Ù„ÙØ¸|Ù…ÙØ±Ø¯Ø©|Ø¹Ø¨Ø§Ø±Ø©)\s+([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
]

# ------------- 1.5. Two-word patterns for difference questions --------------------
_TWO_WORD_PATTERNS: list[re.Pattern] = [
    # Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† X Ùˆ Y (where Y might start with Ùˆ)
    re.compile(
        r'(?:Ù…Ø§\s+Ø§Ù„ÙØ±Ù‚\s+Ø¨ÙŠÙ†\s+)'
        r'([^\s\?\.ØŒØŸ]+)\s+Ùˆ\s*([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Ù‡Ù„ Ù‡Ù†Ø§Ùƒ ÙØ±Ù‚ Ø¨ÙŠÙ† X Ùˆ Y (where Y might start with Ùˆ)
    re.compile(
        r'(?:Ù‡Ù„\s+Ù‡Ù†Ø§Ùƒ\s+ÙØ±Ù‚\s+Ø¨ÙŠÙ†\s+)'
        r'([^\s\?\.ØŒØŸ]+)\s+Ùˆ\s*([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† X Ùˆ Y (where Y might start with Ùˆ)
    re.compile(
        r'(?:Ø§Ù„ÙØ±Ù‚\s+Ø¨ÙŠÙ†\s+)'
        r'([^\s\?\.ØŒØŸ]+)\s+Ùˆ\s*([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Ù…Ø§ Ø§Ù„ÙØ±Ù‚ ÙÙŠ Ù…Ø¹Ù†Ù‰ X Ùˆ Y (where Y might start with Ùˆ)
    re.compile(
        r'(?:Ù…Ø§\s+Ø§Ù„ÙØ±Ù‚\s+ÙÙŠ\s+Ù…Ø¹Ù†Ù‰\s+)'
        r'([^\s\?\.ØŒØŸ]+)\s+Ùˆ\s*([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Generic pattern for "difference between X and Y"
    re.compile(
        r'(?:.*?ÙØ±Ù‚.*?Ø¨ÙŠÙ†\s+)'
        r'([^\s\?\.ØŒØŸ]+)\s+Ùˆ\s*([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
    # Alternative pattern for cases where Ùˆ is attached to the second word
    re.compile(
        r'(?:.*?ÙØ±Ù‚.*?Ø¨ÙŠÙ†\s+)'
        r'([^\s\?\.ØŒØŸ]+)\s+Ùˆ([^\s\?\.ØŒØŸ]+)',
        re.I,
    ),
]

# ------------- 2. GPT-fallback ---------------------------
_MODEL = "gpt-4o-mini-2024-07-18"
_TIMEOUT_S = 12
_CONF_THRESHOLD = 0.45

_SYS_PROMPT = (
    "You are a precise extractor. "
    "Given an Arabic user question, return ONLY the Qur'anic word "
    "requested. For words starting with hamza (Ø£, Ø¥, Ø¢), preserve the hamza exactly as written. "
    "Respond JSON: {\"word\":\"...\",\"confidence\":0.88}."
)

_SYS_PROMPT_TWO_WORDS = (
    "You are a precise extractor for difference questions. "
    "Given an Arabic question asking about the difference between two words, "
    "return ONLY the two words separated by '|'. "
    "For words starting with hamza (Ø£, Ø¥, Ø¢), preserve the hamza exactly as written. "
    "Respond JSON: {\"words\":\"word1|word2\",\"confidence\":0.88}."
)


def _regex_layer(text: str) -> Optional[str]:
    print(f"\nðŸ” Extracting word from: {text}")
    for i, p in enumerate(_PATTERNS):
        m = p.search(text)
        if m:
            word = m.group(1)
            print(f"Pattern {i} matched: {word}")
            # Ignore common relative pronouns accidentally captured (e.g. "Ø°ÙŠ", "Ø§Ù„Ø°ÙŠ")
            if word in {"Ø°ÙŠ", "Ø§Ù„Ø°ÙŠ", "Ø§Ù„ØªÙŠ", "Ø§Ù„Ø°ÙŠÙ†", "Ø§Ù„Ù„Ø°Ø§Ù†", "Ø§Ù„Ù„Ø°ÙŠÙ†", "Ø§Ù„Ù„ØªØ§Ù†", "Ø§Ù„Ù„Ø§ØªÙŠ", "Ø§Ù„Ù„Ø§Ø¦ÙŠ"}:
                continue  # keep searching other patterns
            return word
    print("No pattern matched")
    return None


def _regex_layer_two_words(text: str) -> Optional[Tuple[str, str]]:
    print(f"\nðŸ” Extracting two words from: {text}")
    for i, p in enumerate(_TWO_WORD_PATTERNS):
        m = p.search(text)
        if m:
            word1 = m.group(1)
            word2 = m.group(2)

            # Do NOT strip initial letters; patterns already exclude the conjunctive Ùˆ
            print(f"Two-word pattern {i} matched: {word1} and {word2}")
            return word1, word2
    print("No two-word pattern matched")
    return None


def _llm_layer(txt: str) -> tuple[Optional[str], float]:
    try:
        rsp = client.chat.completions.create(
            model=_MODEL,
            messages=[
                {"role": "system", "content": _SYS_PROMPT},
                {"role": "user", "content": txt},
            ],
            max_tokens=20,
            temperature=0.0,
            timeout=_TIMEOUT_S,
        )
        data = json.loads(rsp.choices[0].message.content)
        return data.get("word"), float(data.get("confidence", 0))
    except Exception as err:  # pragma: no cover
        print(f"[LLM-extract] {type(err).__name__}: {err}", file=sys.stderr)
        return None, 0.0


def _llm_layer_two_words(txt: str) -> tuple[Optional[Tuple[str, str]], float]:
    try:
        rsp = client.chat.completions.create(
            model=_MODEL,
            messages=[
                {"role": "system", "content": _SYS_PROMPT_TWO_WORDS},
                {"role": "user", "content": txt},
            ],
            max_tokens=30,
            temperature=0.0,
            timeout=_TIMEOUT_S,
        )
        data = json.loads(rsp.choices[0].message.content)
        words_str = data.get("words", "")
        if "|" in words_str:
            word1, word2 = words_str.split("|", 1)
            return (word1.strip(), word2.strip()), float(data.get("confidence", 0))
        return None, 0.0
    except Exception as err:  # pragma: no cover
        print(f"[LLM-extract-two-words] {type(err).__name__}: {err}", file=sys.stderr)
        return None, 0.0


# ----------- 3. public API --------------------------------
def extract_word(question: str) -> Optional[str]:
    """
    Return the word or `None` if extraction fails
    (â†’ pipeline will ask the user explicitly).
    """
    # layer 1
    w = _regex_layer(question)
    if w:
        return w

    # layer 2
    llm_word, conf = _llm_layer(question)
    if llm_word and conf >= _CONF_THRESHOLD:
        return llm_word

    # layer 3
    return None


def extract_two_words(question: str) -> Optional[Tuple[str, str]]:
    """
    Return a tuple of two words or `None` if extraction fails
    (â†’ pipeline will ask the user explicitly).
    """
    # layer 1: regex patterns
    words = _regex_layer_two_words(question)
    if words:
        return words

    # layer 2: LLM fallback
    llm_words, conf = _llm_layer_two_words(question)
    if llm_words and conf >= _CONF_THRESHOLD:
        return llm_words

    # layer 3: fallback
    return None